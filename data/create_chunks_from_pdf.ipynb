{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97bc84ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 123\u001b[39m\n\u001b[32m    120\u001b[39m output_json = \u001b[33m\"\u001b[39m\u001b[33mnephro_chunks.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# CORRECTED FUNCTION CALL: No colon, use defined variables\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[43mextract_clean_paragraphs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_pdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_json\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mextract_clean_paragraphs\u001b[39m\u001b[34m(pdf_path, json_output_path)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col_box \u001b[38;5;129;01min\u001b[39;00m [left_box, right_box]:\n\u001b[32m     28\u001b[39m     crop = page.crop(bbox=col_box)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     words = \u001b[43mcrop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_words\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_tolerance\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tolerance\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_blank_chars\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m words:\n\u001b[32m     32\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prk91\\test\\Lib\\site-packages\\pdfplumber\\page.py:536\u001b[39m, in \u001b[36mPage.extract_words\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mextract_words\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs: Any) -> T_obj_list:\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m utils.extract_words(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchars\u001b[49m, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prk91\\test\\Lib\\site-packages\\pdfplumber\\container.py:52\u001b[39m, in \u001b[36mContainer.chars\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchars\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> T_obj_list:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobjects\u001b[49m.get(\u001b[33m\"\u001b[39m\u001b[33mchar\u001b[39m\u001b[33m\"\u001b[39m, [])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prk91\\test\\Lib\\site-packages\\pdfplumber\\page.py:712\u001b[39m, in \u001b[36mCroppedPage.objects\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_objects\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    710\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._objects\n\u001b[32m    711\u001b[39m \u001b[38;5;28mself\u001b[39m._objects: Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list] = {\n\u001b[32m--> \u001b[39m\u001b[32m712\u001b[39m     k: \u001b[38;5;28mself\u001b[39m._crop_fn(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent_page\u001b[49m\u001b[43m.\u001b[49m\u001b[43mobjects\u001b[49m.items()\n\u001b[32m    713\u001b[39m }\n\u001b[32m    714\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._objects\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prk91\\test\\Lib\\site-packages\\pdfplumber\\page.py:346\u001b[39m, in \u001b[36mPage.objects\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_objects\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    345\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._objects\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m \u001b[38;5;28mself\u001b[39m._objects: Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._objects\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prk91\\test\\Lib\\site-packages\\pdfplumber\\page.py:443\u001b[39m, in \u001b[36mPage.parse_objects\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse_objects\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list]:\n\u001b[32m    442\u001b[39m     objects: Dict[\u001b[38;5;28mstr\u001b[39m, T_obj_list] = {}\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_layout_objects(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayout\u001b[49m._objs):\n\u001b[32m    444\u001b[39m         kind = obj[\u001b[33m\"\u001b[39m\u001b[33mobject_type\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    445\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m kind \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33manno\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prk91\\test\\Lib\\site-packages\\pdfplumber\\page.py:266\u001b[39m, in \u001b[36mPage.layout\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    264\u001b[39m interpreter = PDFPageInterpreter(\u001b[38;5;28mself\u001b[39m.pdf.rsrcmgr, device)\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     \u001b[43minterpreter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpage_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PdfminerException(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prk91\\test\\Lib\\site-packages\\pdfminer\\pdfinterp.py:1210\u001b[39m, in \u001b[36mPDFPageInterpreter.process_page\u001b[39m\u001b[34m(self, page)\u001b[39m\n\u001b[32m   1208\u001b[39m     ctm = (\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, -x0, -y0)\n\u001b[32m   1209\u001b[39m \u001b[38;5;28mself\u001b[39m.device.begin_page(page, ctm)\n\u001b[32m-> \u001b[39m\u001b[32m1210\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrender_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mctm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[38;5;28mself\u001b[39m.device.end_page(page)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prk91\\test\\Lib\\site-packages\\pdfminer\\pdfinterp.py:1231\u001b[39m, in \u001b[36mPDFPageInterpreter.render_contents\u001b[39m\u001b[34m(self, resources, streams, ctm)\u001b[39m\n\u001b[32m   1229\u001b[39m \u001b[38;5;28mself\u001b[39m.init_resources(resources)\n\u001b[32m   1230\u001b[39m \u001b[38;5;28mself\u001b[39m.init_state(ctm)\n\u001b[32m-> \u001b[39m\u001b[32m1231\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstreams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prk91\\test\\Lib\\site-packages\\pdfminer\\pdfinterp.py:1241\u001b[39m, in \u001b[36mPDFPageInterpreter.execute\u001b[39m\u001b[34m(self, streams)\u001b[39m\n\u001b[32m   1239\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m   1240\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1241\u001b[39m         (_, obj) = \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnextobject\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1242\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m PSEOF:\n\u001b[32m   1243\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prk91\\test\\Lib\\site-packages\\pdfminer\\psparser.py:659\u001b[39m, in \u001b[36mPSStackParser.nextobject\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    657\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    658\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m659\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    660\u001b[39m obj = \u001b[38;5;28mself\u001b[39m.results.pop(\u001b[32m0\u001b[39m)\n\u001b[32m    661\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prk91\\test\\Lib\\site-packages\\pdfminer\\pdfinterp.py:321\u001b[39m, in \u001b[36mPDFContentParser.flush\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mflush\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpopall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\prk91\\test\\Lib\\site-packages\\pdfminer\\psparser.py:564\u001b[39m, in \u001b[36mPSStackParser.add_results\u001b[39m\u001b[34m(self, *objs)\u001b[39m\n\u001b[32m    561\u001b[39m     \u001b[38;5;28mself\u001b[39m.curstack = []\n\u001b[32m    562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m objs\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_results\u001b[39m(\u001b[38;5;28mself\u001b[39m, *objs: PSStackEntry[ExtraT]) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    565\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    566\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33madd_results: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, objs)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import json\n",
    "import statistics\n",
    "\n",
    "def extract_clean_paragraphs(pdf_path, json_output_path):\n",
    "    extracted_data = []\n",
    "\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for i, page in enumerate(pdf.pages):\n",
    "                # 1. GET DIMENSIONS & IGNORE HEADER\n",
    "                # page.bbox returns (x0, top, x1, bottom)\n",
    "                # We start 'top' at 50 to skip the header (e.g., \"SECTION I...\")\n",
    "                x0, top, x1, bottom = page.bbox\n",
    "                header_cutoff = top + 50 \n",
    "                \n",
    "                width = x1 - x0\n",
    "                midpoint = x0 + (width / 2)\n",
    "                \n",
    "                # Define Column Boxes (Left and Right)\n",
    "                left_box = (x0, header_cutoff, midpoint, bottom)\n",
    "                right_box = (midpoint, header_cutoff, x1, bottom)\n",
    "                \n",
    "                page_paragraphs = []\n",
    "                \n",
    "                # Process Left Column then Right Column\n",
    "                for col_box in [left_box, right_box]:\n",
    "                    crop = page.crop(bbox=col_box)\n",
    "                    words = crop.extract_words(x_tolerance=3, y_tolerance=3, keep_blank_chars=False)\n",
    "                    \n",
    "                    if not words:\n",
    "                        continue\n",
    "\n",
    "                    # 2. CLUSTER WORDS INTO LINES\n",
    "                    lines = []\n",
    "                    current_line = [words[0]]\n",
    "                    for word in words[1:]:\n",
    "                        if abs(word['top'] - current_line[-1]['top']) < 5:\n",
    "                            current_line.append(word)\n",
    "                        else:\n",
    "                            lines.append(current_line)\n",
    "                            current_line = [word]\n",
    "                    lines.append(current_line)\n",
    "\n",
    "                    # 3. CALCULATE MARGINS (CRITICAL STEP)\n",
    "                    all_x0 = [line[0]['x0'] for line in lines]\n",
    "                    all_x1 = [line[-1]['x1'] for line in lines]\n",
    "                    \n",
    "                    # Using median as a robust estimate for flush margin\n",
    "                    col_left_margin = statistics.median(all_x0)\n",
    "                    col_right_margin = statistics.median(all_x1)\n",
    "\n",
    "                    # 4. RECONSTRUCT PARAGRAPHS\n",
    "                    current_para_text = \"\"\n",
    "                    \n",
    "                    for idx, line in enumerate(lines):\n",
    "                        line_text = \" \".join([w['text'] for w in line])\n",
    "                        line_start = line[0]['x0']\n",
    "                        line_end = line[-1]['x1']\n",
    "                        line_top = line[0]['top']\n",
    "                        \n",
    "                        is_new_para = False\n",
    "                        \n",
    "                        if idx == 0:\n",
    "                            is_new_para = True\n",
    "                        else:\n",
    "                            prev_line = lines[idx-1]\n",
    "                            prev_end = prev_line[-1]['x1']\n",
    "                            prev_bottom = prev_line[0]['bottom']\n",
    "                            \n",
    "                            # CHECK A: INDENTATION\n",
    "                            if (line_start - col_left_margin) > 10:\n",
    "                                is_new_para = True\n",
    "                            \n",
    "                            # CHECK B: PREVIOUS LINE SHORT (End of sentence)\n",
    "                            elif (col_right_margin - prev_end) > 10:\n",
    "                                is_new_para = True\n",
    "                                \n",
    "                            # CHECK C: VERTICAL GAP (Headers/Sections)\n",
    "                            elif (line_top - prev_bottom) > 12:\n",
    "                                is_new_para = True\n",
    "                                \n",
    "                            # CHECK D: IS HEADER (e.g. \"NEPHRONS\")\n",
    "                            elif line_text.isupper() and len(line_text.split()) < 5:\n",
    "                                is_new_para = True\n",
    "\n",
    "                        # APPEND TEXT\n",
    "                        if is_new_para:\n",
    "                            if current_para_text:\n",
    "                                page_paragraphs.append(current_para_text.strip())\n",
    "                            current_para_text = line_text\n",
    "                        else:\n",
    "                            # Merge logic: fix hyphenation\n",
    "                            if current_para_text.endswith('-'):\n",
    "                                current_para_text = current_para_text[:-1] + line_text\n",
    "                            else:\n",
    "                                current_para_text += \" \" + line_text\n",
    "                        \n",
    "                    # Flush last paragraph of column\n",
    "                    if current_para_text:\n",
    "                        page_paragraphs.append(current_para_text.strip())\n",
    "\n",
    "                extracted_data.append({\n",
    "                    \"page_number\": i + 1,\n",
    "                    \"paragraphs\": page_paragraphs\n",
    "                })\n",
    "\n",
    "        with open(json_output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(extracted_data, f, indent=4, ensure_ascii=False)\n",
    "            \n",
    "        print(f\"Extraction complete. Saved to {json_output_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The PDF file '{pdf_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "input_pdf = \"comprehensive-clinical-nephrology-20-1490.pdf\"\n",
    "output_json = \"nephro_chunks.json\"\n",
    "\n",
    "# CORRECTED FUNCTION CALL: No colon, use defined variables\n",
    "extract_clean_paragraphs(input_pdf, output_json)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
